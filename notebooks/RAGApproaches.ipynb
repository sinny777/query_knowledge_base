{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e0d795-567a-4e9b-95f6-44b120c76ad4",
   "metadata": {},
   "source": [
    "# Retrieval Augment Generation (RAG) Approaches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec148ed-b104-4d52-807b-800f73b1a95a",
   "metadata": {},
   "source": [
    "## Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "801064b0-997e-4b61-96a1-b6b38010627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "logger.addHandler(logging.StreamHandler(stream=sys.stdout))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dadaca3-24c7-4450-9262-991d26be9c0d",
   "metadata": {},
   "source": [
    "### Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf6655-6c84-4436-a61a-4a81b935e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PyPDF2 import PdfWriter, PdfReader\n",
    "# input_pdf = PdfReader(\"../datasets/presentations/innovation-onepagers-ibm.pdf\")\n",
    "\n",
    "# index = 1\n",
    "# for page in input_pdf.pages:\n",
    "#     if index > 0:\n",
    "#         output = PdfWriter()\n",
    "#         output.add_page(page)\n",
    "#         with open('../datasets/presentations/splits/slide'+str(index) +'.pdf', \"wb\") as output_stream:\n",
    "#             output.write(output_stream)\n",
    "#     index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb845e2d-48e3-486e-bf36-6bdaaebadfb3",
   "metadata": {},
   "source": [
    "## RAG With VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5ce524-f00e-4212-94a1-ba68a2c61d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gurvindersingh/Documents/development/repositories/GSI/NTTData/query_knowledge_base/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "# from langchain.chains import load_qa_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "# from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import sentence_transformers: Please install sentence-transformers package.\")\n",
    "\n",
    "try:\n",
    "    import chromadb\n",
    "    from chromadb.api.types import EmbeddingFunction\n",
    "except ImportError:\n",
    "    raise ImportError(\"Could not import chromdb: Please install chromadb package.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a07890f3-7eb9-429b-9382-1cfedbff0d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /var/folders/c7/kjprf9q109x1lhfjfm_h6jfr0000gn/T/tmph6j3sal1\n",
      "Created a temporary directory at /var/folders/c7/kjprf9q109x1lhfjfm_h6jfr0000gn/T/tmph6j3sal1\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /var/folders/c7/kjprf9q109x1lhfjfm_h6jfr0000gn/T/tmph6j3sal1/_remote_module_non_scriptable.py\n",
      "Writing /var/folders/c7/kjprf9q109x1lhfjfm_h6jfr0000gn/T/tmph6j3sal1/_remote_module_non_scriptable.py\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device: cpu\n",
      "Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232f13dc-e0b7-4be4-9f96-16774533fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "embedding_function = MiniLML6V2EmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"../vectors\")\n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\n",
    "    name=\"search\", \n",
    "    get_or_create=True,\n",
    "    embedding_function=embedding_function\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "966ec873-16de-4f9b-a84d-fb988e594c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(DATASET_DIR):\n",
    "    # DATASET_DIR = \"../datasets/presentations\"\n",
    "    loader = DirectoryLoader(DATASET_DIR, glob='*.pdf')\n",
    "    documents = loader.load()\n",
    "    logger.info(f'You have {len(documents)} document(s) in your data')\n",
    "    logger.info(f'There are {len(documents[0].page_content)} characters in first page')\n",
    "    # logger.info(f'First Page Content: \\n\\n{documents[0].page_content} \\n\\n')\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    logger.info(f'We have total documents after split: {len(docs)}')\n",
    "\n",
    "    ids = []\n",
    "    metadatas = []\n",
    "    documents = []\n",
    "    for doc in docs:\n",
    "        ids.append(str(uuid.uuid1()))\n",
    "        documents.append(doc.page_content)\n",
    "        file_name = os.path.basename(doc.metadata['source'])\n",
    "        metadatas.append({'source': file_name})   \n",
    "        # self._collection.add(ids=[str(uuid.uuid1())], metadatas=doc.metadata, documents=doc.page_content)\n",
    "    \n",
    "    chroma_collection.add(ids=ids, metadatas=metadatas, documents=documents)   \n",
    "    try:\n",
    "        chroma_client.persist() \n",
    "        # del chroma_client\n",
    "        # del chroma_collection\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5dcfbe2-d6b5-4e14-9b73-3a341e5ce985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:You have 58 document(s) in your data\n",
      "You have 58 document(s) in your data\n",
      "INFO:root:There are 1780 characters in first page\n",
      "There are 1780 characters in first page\n",
      "INFO:root:We have total documents after split: 109\n",
      "We have total documents after split: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:01<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'SegmentAPI' object has no attribute 'persist'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "load_documents(\"../datasets/presentations/splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a796f882-ffee-4dae-a6af-b3e26685dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchContextUsingVectorDB(query):\n",
    "    docs = []\n",
    "    result = chroma_collection.query(query_texts=query, n_results=2, include=[\"documents\",\"metadatas\"])    \n",
    "    # print(json.dumps(result, indent=2))\n",
    "    for c in result[\"documents\"][0]:    \n",
    "        pageContent = ''.join(c)\n",
    "        # print(pageContent)\n",
    "        doc = Document(page_content = pageContent);\n",
    "        docs.append(doc)\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e479bb3-b71d-46b4-bf1a-44a1456d8c97",
   "metadata": {},
   "source": [
    "### Test Results from VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84331e33-a900-493a-b432-b608d57dd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 46.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide support to counselors and assist them during conversation with children\n",
      "\n",
      "Counselors/supporters might not be specialists in all areas, often only in 2- 3 areas. Topics outside their scope of comfort are difficult. An AI can help them on topics where they lack knowledge\n",
      "\n",
      "A generic “Ethical Advisory Agent” which uses the Federate Question Answer (Bot of Bots) approach and ethical AI principles to help counsellors and case workers help their clients in real time – fast and fair. Based on the asset created for “Children's Welfare” in 2019 – in combination with eVA and FQA.\n",
      "\n",
      "AI platform with opportunity for federated learning across related domains\n",
      "\n",
      "Help tool for guidance material and advice suggestion\n",
      "\n",
      "AI as a service: Plugin to 3rd party chat/support tools \n",
      "\n",
      " ******************* \n",
      "\n",
      "\n",
      "Ethical Advisor – Helping children with AI\n",
      "\n",
      "itelligence uses AI technology to assist child counselors in their interaction with children. The goal of the AI is to make the counselors more efficient by automating their manual work taking notes during conversations with children and classifying the topics of the conversation afterwards.\n",
      "\n",
      "Business need\n",
      "\n",
      "Solution\n",
      "\n",
      "Outcomes\n",
      "\n",
      "Slow response rates in child welfare organizations: 130,000 calls from children are missed each year at the Children's Welfare organisation. They are looking at innovative ways for optimizing their organization and were interested in how AI could help doing this. Based on design thinking workshop, the case with the Ethical Advisor was identified\n",
      "\n",
      "Handling wait time with\n",
      "\n",
      "children while in queue on the phone (children may be in the queue up to two hours waiting for counsel)\n",
      "\n",
      "Assistance to the counselors using AI\n",
      "\n",
      "NLP for children’s language (generic)\n",
      "\n",
      "Ethical ML principles (generic)\n",
      "\n",
      "Real-time advisory engine (the AI) \n",
      "\n",
      " ******************* \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give me summary of the AI Learning Helper case?\"\n",
    "result = fetchContextUsingVectorDB(query)\n",
    "for c in result:    \n",
    "    print(f\"{c.page_content} \\n\\n ******************* \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc75d6-9ba0-4af7-9773-eae1fb0edfe5",
   "metadata": {},
   "source": [
    "## RAG With IBM Watson Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eec0914a-e046-46a5-b91b-9480eadaee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson import DiscoveryV2\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "import text_extensions_for_pandas as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6b9eb92-06cc-4ee9-819b-fcf8597f21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "env_path = Path('../.env')\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "discovery = None\n",
    "WD_VERSION = '2023-03-31'\n",
    "WD_PROJECT_ID = os.getenv(\"WD_PROJECT_ID\", None)\n",
    "WD_COLLECTION_ID = os.getenv(\"WD_COLLECTION_ID\", \"0952b45a-15b2-3b48-0000-018ac070b2b4\")\n",
    "\n",
    "WD_THRESHOLD = 0.06\n",
    "SHOW_WD_RESULTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d89ee7a-f2f7-4823-a829-d43ac82e007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_wd():\n",
    "    WD_API_KEY = os.getenv(\"WD_API_KEY\", None)\n",
    "    WD_ENDPOINT = os.getenv(\"WD_ENDPOINT\", None)\n",
    "    if WD_API_KEY is None or WD_ENDPOINT is None:\n",
    "        print(\"Either api_key or api_url is None. Please make sure your credentials are correct.\")\n",
    "    \n",
    "    authenticator = IAMAuthenticator(WD_API_KEY)\n",
    "    global discovery\n",
    "    discovery = DiscoveryV2(\n",
    "        version=WD_VERSION,\n",
    "        authenticator=authenticator\n",
    "    )\n",
    "    return discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3866f9a-ee1f-4bc9-95f0-99891a91e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'collections': [{'name': 'cos-search', 'collection_id': '0952b45a-15b2-3b48-0000-018ac070b2b4'}, {'name': 'CarManuals', 'collection_id': '8a630ea5-f1ea-fcb5-0000-018aa8a3e4f2'}, {'name': 'TechSupportFAQ', 'collection_id': 'e1d38500-4eea-126f-0000-01899be30019'}, {'name': 'BusinessSlides', 'collection_id': '80abebd4-c560-8257-0000-018ac03e6553'}]}\n"
     ]
    }
   ],
   "source": [
    "init_wd()\n",
    "collections = discovery.list_collections(\n",
    "  project_id=WD_PROJECT_ID\n",
    ").get_result()\n",
    "\n",
    "print(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66cf2194-f5cb-496a-8d2f-515985834ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WD_COLLECTION_ID = \"0952b45a-15b2-3b48-0000-018ac070b2b4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b9ab77b-518d-4c8d-95ba-94a7b62d8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_wd(payload: any):\n",
    "    global discovery\n",
    "    if(discovery is None):\n",
    "        discovery = init_wd()\n",
    "    discovery_results = discovery.query(\n",
    "        project_id = payload['project_id'],\n",
    "        collection_ids = payload['collection_ids'],\n",
    "        natural_language_query= payload['query'],\n",
    "        count = 3,\n",
    "        return_ = [\"metadata.source.SourceUrl\",\"document_id\",\"extracted_metadata.filename\", \"title\", \"text\", \"BusinessNeeds\", \"Solutions\", \"Outcomes\"]\n",
    "    ).get_result()\n",
    "\n",
    "    # print(json.dumps(discovery_results, indent=2))\n",
    "    \n",
    "    return discovery_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d04b376-9d9c-4f0e-9365-46dcea176da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAsList(textArr, joinText=False):\n",
    "    result = \"\"\n",
    "    # print(f\"Input textArr: {textArr}\")\n",
    "    if textArr is None or len(textArr) == 0:\n",
    "        # print(f\"RETURNING EMPTY: >> {textArr}\")\n",
    "        return \"\"\n",
    "\n",
    "    if len(textArr) == 1:\n",
    "        return textArr[0]\n",
    "\n",
    "    if joinText is True:\n",
    "        result = ' '.join(textArr) + \"\\n\"\n",
    "        # print(f\"joinText: {joinText}, so RETURN RESULT: {result}\")\n",
    "        return result\n",
    "    \n",
    "    index = 0\n",
    "    for text in textArr:\n",
    "        temp = text.encode().decode(\"utf-8\").replace(u\"\\u2022\", \"\")\n",
    "        temp = temp.strip()\n",
    "        if len(temp) > 5:\n",
    "            if index > 0:\n",
    "                result =  f\"{result} {index}: {temp} \\n\"\n",
    "            else:\n",
    "                result =  f\"\\n{result} {temp} \\n\"\n",
    "            index = index + 1        \n",
    "\n",
    "    # print(f\"RETURNING RESULT: >> {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd3b11-55bc-42a5-a8a2-82afdb442924",
   "metadata": {},
   "source": [
    "## Using the Re-Ranker (Currently not implemented)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed7b122-dccd-449d-be14-b4780745e90f",
   "metadata": {},
   "source": [
    "### Good Article for Re-Ranking the results\n",
    "\n",
    "[Improving RAG (Retrieval Augmented Generation) Answer Quality with Re-ranker](https://medium.com/towards-generative-ai/improving-rag-retrieval-augmented-generation-answer-quality-with-re-ranker-55a19931325)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca010423-2fff-4a93-8a67-13bf1acd7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from primeqa.components.reranker.colbert_reranker import ColBERTReranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a702b177-b7c2-4dce-a07d-67a24c9fb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_context_from_wd(query):\n",
    "    payload = {\n",
    "            \"query\": query,\n",
    "            \"project_id\": WD_PROJECT_ID,\n",
    "            \"collection_ids\": [WD_COLLECTION_ID]\n",
    "        }\n",
    "    discovery_results = query_wd(payload)    \n",
    "    docs = []\n",
    "\n",
    "    if SHOW_WD_RESULTS:\n",
    "        print(json.dumps(discovery_results, indent=2))\n",
    "\n",
    "    for c in discovery_results['results']:\n",
    "\n",
    "        if c['result_metadata']['confidence'] <= WD_THRESHOLD:\n",
    "            print(f\"Skipping Document: {c['document_id'][0]}\")\n",
    "            continue\n",
    "\n",
    "        if 'title' in c:\n",
    "            pageContent = \"Title: \" +showAsList(c['title'], joinText=True)\n",
    "        if 'text' in c:\n",
    "            pageContent += showAsList(c['text'], joinText=True)             \n",
    "        if 'Solutions' in c:\n",
    "            pageContent += showAsList(c['Solutions'])\n",
    "        if 'Outcomes' in c:\n",
    "            pageContent += showAsList(c['Outcomes'])\n",
    "        if 'BusinessNeeds' in c:\n",
    "            pageContent += showAsList(c['BusinessNeeds'])\n",
    "        pageContent += \"\\n\\n\\n\"\n",
    "      \n",
    "        doc = Document(page_content = pageContent);\n",
    "        docs.append(doc)\n",
    "    return docs  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f3b76-b374-4c11-a7e6-b1548d20a355",
   "metadata": {},
   "source": [
    "### Test Results from IBM Watson Discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e33167ee-dd22-4684-b70b-18cdefe718b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Document: c\n",
      "Lab Preview Home School Helper\n",
      "The “Home School Helper” is an artificial intelligent companion living on a screen or in a virtual reality environment. Each student will have their own. T IM&C\n",
      " Solution \n",
      " 1: Just like a real teacher, the Home School Helper understands the needs of the child and the context of its learning journey. It will be able to understand the child's emotions and change teaching strategy if, for example, the helper detects that the child is frustrated, de-motivated or does not have the right learning flow Tech focus: \n",
      " 2: IoT/Intelligent Edge, User Experience, Data Intelligence (Edge AI), Ethical AI, IoT integrating with Humans, Robotized processes \n",
      "\n",
      " Outcomes \n",
      " 1: Potential: 50% reduction in cost of homeschooling, resulting in a total cost saving of 5% of a typical school budget. \n",
      " 2: Enhanced working environment for teachers. \n",
      " 3: Enhanced learning experience and subject knowledge for children with home schooling. \n",
      "\n",
      " Lessons & exercises \n",
      " 1: Child's progress \n",
      " 2: Business need \n",
      " 3: Homeschooling is very expensive and students who cannot attend school do not get the same quality of education as normal children The current situation with lock-down and reduced schooling has made this topic even more relevant \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " ******************* \n",
      "\n",
      "\n",
      "AI Learning Helper – The future of personalised education\n",
      "Enhanced learning experience and subject knowledge for pupils Enhanced working environment for teachers Improving the lives of children, teachers and parents 50% estimated reduction in cost of homeschooling ® SAP Innovation Awards 2021 Winne\n",
      " Solution \n",
      " 1: The project was organized very streamlined and has overall ties to the preceding NTTfunded project Frontline AI. \n",
      " 2: The digital human platform created in the Frontline AI project as the technical foundation for this project. \n",
      "\n",
      " Outcomes \n",
      " 1: Personalized Education with the AI Learning Helper -YouTube \n",
      "\n",
      " Business need \n",
      " 1: There can be many different reasons why children cannot attend school. Disability, temporary illness, psychological problems, parent's choice or a pandemic.  Studying at home isn’t easy, as children miss learning with friends, feel less motivated and more distracted.  Homeschooling is very \n",
      " 2: expensive and students who cannot attend school do not get the same quality of education as normal children.  The current situation with lockdown and reduced schooling has made this topic even more relevant than ever \n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " ******************* \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"Can you give me summary of the AI Learning Helper case ?\"\n",
    "result = fetch_context_from_wd(query)\n",
    "for c in result:    \n",
    "    print(f\"{c.page_content} \\n\\n ******************* \\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f9b1e-b0e8-4030-9548-d0c44a7e96c7",
   "metadata": {},
   "source": [
    "## Using IBM Watsonx.ai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a43fec4-2752-41e5-97b7-7b7fa20d1a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a01092b-0c4f-4aeb-bede-ceef31c4e60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# env_path = Path('../app') / '.env'\n",
    "# load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "IBM_CLOUD_API_KEY = os.getenv(\"IBM_CLOUD_API_KEY\", None)\n",
    "WATSONX_AI_ENDPOINT = os.getenv(\"WATSONX_AI_ENDPOINT\", None)\n",
    "WX_PROJECT_ID = os.getenv(\"WX_PROJECT_ID\", None)\n",
    "\n",
    "wx_credentials = {\n",
    "    \"url\": WATSONX_AI_ENDPOINT,\n",
    "    \"apikey\": IBM_CLOUD_API_KEY\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46d00000-24f4-4d2d-a1a4-f99a7f6fb5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:ibm_watson_machine_learning.client:Client successfully initialized\n",
      "Client successfully initialized\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MAX_NEW_TOKENS: 500,\n",
    "    GenParams.MIN_NEW_TOKENS: 60,\n",
    "    \"repetition_penalty\": 2\n",
    "    # GenParams.REPETITION_PENALTY: 2\n",
    "    # GenParams.TEMPERATURE: 0.5,\n",
    "    # GenParams.TOP_K: 50,\n",
    "    # GenParams.TOP_P: 1\n",
    "}\n",
    "\n",
    "\n",
    "wx_model = Model(\n",
    "    model_id=ModelTypes.FLAN_UL2, \n",
    "    params=parameters, \n",
    "    credentials=wx_credentials,\n",
    "    project_id=WX_PROJECT_ID)\n",
    "\n",
    "\n",
    "watsonx_llm = WatsonxLLM(model=wx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f97fb26-7c87-4ba4-8ab9-0e703a22a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(query, context):\n",
    "   \n",
    "    qa_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\\n\"\"\"\n",
    "  \n",
    "    PROMPT = PromptTemplate(\n",
    "        template=qa_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "    \n",
    "    chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "    chain = load_qa_chain(watsonx_llm, chain_type=\"stuff\", verbose=True)\n",
    "    # chain = load_qa_chain(watsonx_llm, chain_type=\"stuff\", prompt=PROMPT, verbose=True)\n",
    "    # chain = RetrievalQA.from_chain_type(llm=watsonx_llm, chain_type=\"stuff\", chain_type_kwargs=chain_type_kwargs)\n",
    "    \n",
    "    result = chain.run(input_documents=context, question=query)\n",
    "    print(result)\n",
    "    \n",
    "    # chain({\"input_documents\": docs, \"question\": payload['query']}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8e354f5-0de1-4db5-8fd7-771e745ba1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Title: W i n g c o p t e r   |   Z a m w a m b a\n",
      "Drone delivery platform to supply rural areas in Malawi (Africa) with medical goods and samples\n",
      " Solution \n",
      " 1: Delivery drones (VTOL) for medical goods transfers to health facilities  Payload up to 6 kg, speed up to 120 kph  Cold chain transports possible  CO2 neutral transportation  Platform for flight scheduling and medical goods orders  Based on SAP BTP, it.XIA and \n",
      " 2: Microsoft Azure \n",
      "\n",
      " Outcomes \n",
      " 1: No dependence on road/land infrastructure  Delivery times for medical goods and samples went down from a day’s march to approx. \n",
      " 2: 20 minutes  Urgent deliveries can be prioritized, e.g. in life threatening situations  Supporting Malawi’s medical supply chain \n",
      "\n",
      " Business need \n",
      " 1: Due to bad infrastructure, many health facilities in Malawi (Africa) have limited or no access to medical infrastructure  Compliance with cold chain limited or not possible  Manual ordering and flight scheduling processes \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Title: AI Learning Helper – The future of personalised education\n",
      "Enhanced learning experience and subject knowledge for pupils Enhanced working environment for teachers Improving the lives of children, teachers and parents 50% estimated reduction in cost of homeschooling ® SAP Innovation Awards 2021 Winne\n",
      " Solution \n",
      " 1: The project was organized very streamlined and has overall ties to the preceding NTTfunded project Frontline AI. \n",
      " 2: The digital human platform created in the Frontline AI project as the technical foundation for this project. \n",
      "\n",
      " Outcomes \n",
      " 1: Personalized Education with the AI Learning Helper -YouTube \n",
      "\n",
      " Business need \n",
      " 1: There can be many different reasons why children cannot attend school. Disability, temporary illness, psychological problems, parent's choice or a pandemic.  Studying at home isn’t easy, as children miss learning with friends, feel less motivated and more distracted.  Homeschooling is very \n",
      " 2: expensive and students who cannot attend school do not get the same quality of education as normal children.  The current situation with lockdown and reduced schooling has made this topic even more relevant than ever \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Title: Lab Preview Business Process Advisor\n",
      "Designed to optimize our customers' business processes in real time, this project finds and suggests areas for process optimization and “automation\". R IM&C\n",
      " Solution \n",
      " 1: Optimizing processes on an actual case basis is the aim of this project, which integrates AI technologies with our classical customer activities Data-driven approach and visualization Standard real-time event extractors for SAP processes Process conformance analysis Process variant analysis Process drill down and bottleneck identification \n",
      " 2: Process AI Cross industry process KPI benchmarks \n",
      "\n",
      " Outcomes \n",
      " 1: Process benchmarking and analysis with identification of root cause and influence analysis Continuous process improvement The quality of processes is improved with full transparency Root causes of poor performance are identified Forecasting of lead time and problems Instant restults and payback through cost savings \n",
      "\n",
      " Business need \n",
      " 1: Even though good Long Short-term Memory (LSTM) models exist for predicting business process path, duration and outcome, these models cannot be leveraged into \"live\" business software and processes as of yet \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question: What were the outcomes of the Wingcopter project?\n",
      "Helpful Answer:\u001b[0m\n",
      "INFO:ibm_watson_machine_learning.wml_resource:Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2022-08-01'\n",
      "Successfully finished generate for url: 'https://us-south.ml.cloud.ibm.com/ml/v1-beta/generation/text?version=2022-08-01'\n",
      "INFO:ibm_watson_machine_learning.foundation_models.extensions.langchain.llm:Output of watsonx.ai call: No dependence on road/land infrastructure Delivery times for medical goods and samples went down from a day’s march to approx. 20 minutes Urgent deliveries can be prioritized, e.g. in life threatening situations Supporting Malawi’s medical supply chain Business need 1: Due to bad infrastructure, many health facilities in Malawi (Africa) have limited or no access to medical infrastructure Compliance with cold chain limited or not possible Manual ordering and flight scheduling processes\n",
      "Output of watsonx.ai call: No dependence on road/land infrastructure Delivery times for medical goods and samples went down from a day’s march to approx. 20 minutes Urgent deliveries can be prioritized, e.g. in life threatening situations Supporting Malawi’s medical supply chain Business need 1: Due to bad infrastructure, many health facilities in Malawi (Africa) have limited or no access to medical infrastructure Compliance with cold chain limited or not possible Manual ordering and flight scheduling processes\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "No dependence on road/land infrastructure Delivery times for medical goods and samples went down from a day’s march to approx. 20 minutes Urgent deliveries can be prioritized, e.g. in life threatening situations Supporting Malawi’s medical supply chain Business need 1: Due to bad infrastructure, many health facilities in Malawi (Africa) have limited or no access to medical infrastructure Compliance with cold chain limited or not possible Manual ordering and flight scheduling processes\n"
     ]
    }
   ],
   "source": [
    "# query = \"If my vehicle has airbags, why should I have to wear safety belts?\"\n",
    "# query = \"How to Wear Safety Belts Properly\"\n",
    "# query = \"What can happen if my shoulder belt is too loose ?\"\n",
    "\n",
    "# query = \"What solutions do we have for Farmbot network ?\"\n",
    "# query = \"Show me the outcomes of our Car Damage Detection solution\"\n",
    "# query = \"What's our take on certifications using blockchain technology ?\"\n",
    "\n",
    "# query = \"What solutions do we have for the Home School Helper?\"\n",
    "# query = \"Do we have any cases where we used drones?\"\n",
    "# query = \"Who’s managing the portfolio?\"\n",
    "query = \"What were the outcomes of the Wingcopter project?\"\n",
    "# query = \"I have a customer that’s interested in the digital assistant. Can you write me a summary of the solution?\"\n",
    "# query = \"Can you give me summary of the AI Learning Helper case ?\"\n",
    "\n",
    "\n",
    "# context = fetchContextUsingVectorDB(query)\n",
    "context = fetch_context_from_wd(query)\n",
    "# print(context)\n",
    "\n",
    "main(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca852c-82c0-4b4e-a209-f842b3a371a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab61be3-7c4f-4757-a2db-cf1859338896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
